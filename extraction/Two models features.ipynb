{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Extracted Features First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AliHaidar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\AliHaidar\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "historyfilename='model/history_model_norm.json'\n",
    "modelweights='model/model_weights_norm.h5'\n",
    "thevars=\"model/MondayDesneNet169/extractedfeatures_norm.pickle\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "#with open(\"densenet121/extractedfeatures.pickle\", \"wb\") as f:\n",
    "#    pickle.dump((Train_Features,Train_Target,Val_Features,Val_Target,Test_Features,Test_Target,model,model_extracted), f)\n",
    "\n",
    "with open(thevars, \"rb\") as f:\n",
    "    Train_Features_A,Train_Target_A,Val_Features_A,Val_Target_A,Test_Features_A,Test_Target_A,model_A,model_extracted_A = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Extracted Features Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyfilename='model/history_model.json'\n",
    "modelweights='model/model_weights.h5'\n",
    "thevars=\"model/MondayDesneNet169/extractedfeatures.pickle\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "#with open(\"densenet121/extractedfeatures.pickle\", \"wb\") as f:\n",
    "#    pickle.dump((Train_Features,Train_Target,Val_Features,Val_Target,Test_Features,Test_Target,model,model_extracted), f)\n",
    "\n",
    "with open(thevars, \"rb\") as f:\n",
    "    Train_Features_B,Train_Target_B,Val_Features_B,Val_Target_B,Test_Features_B,Test_Target_B,model_B,model_extracted_B = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Train_Features=np.concatenate([Train_Features_A,Train_Features_B],axis=1)\n",
    "Train_Target=Train_Target_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Features=np.concatenate([Val_Features_A,Val_Features_B],axis=1)\n",
    "Val_Target=Val_Target_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Features=np.concatenate([Test_Features_A,Test_Features_B],axis=1)\n",
    "Y_test=Test_Target_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def measure_per(y_val,preds,num_classes):\n",
    "    print(accuracy_score(y_val,preds))\n",
    "    print(cohen_kappa_score(y_val,preds))\n",
    "\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, range(num_classes),\n",
    "                              range(num_classes))\n",
    "    print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "# Creating a function to report confusion metrics\n",
    "def confusion_metrics (truvalues,predictions):\n",
    "# save confusion matrix and slice into four pieces\n",
    "    conf_matrix = confusion_matrix(truvalues, predictions)\n",
    "    df_cm = pd.DataFrame(conf_matrix, range(num_classes),\n",
    "                              range(num_classes))\n",
    "    print(df_cm)\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    print('True Positives:', TP)\n",
    "    print('True Negatives:', TN)\n",
    "    print('False Positives:', FP)\n",
    "    print('False Negatives:', FN)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    \n",
    "    # calculate mis-classification\n",
    "    conf_misclassification = 1- conf_accuracy\n",
    "    \n",
    "    # calculate the sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "    # calculate the specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    # calculate precision\n",
    "    conf_precision = (TN / float(TN + FP))\n",
    "    # calculate f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "    print('-'*50)\n",
    "    print(f'Accuracy: {round(conf_accuracy,2)}') \n",
    "    print(f'Mis-Classification: {round(conf_misclassification,2)}') \n",
    "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
    "    print(f'Specificity: {round(conf_specificity,2)}') \n",
    "    print(f'Precision: {round(conf_precision,2)}')\n",
    "    print(f'f_1 Score: {round(conf_f1,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8952866861030127\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from xgboost import plot_importance,plot_tree\n",
    "eval_set = [(Val_Features, Val_Target.ravel())]\n",
    "\n",
    "objective='binary:logistic'\n",
    "eval_metric=[\"aucpr\",'auc']\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(objective=objective,\n",
    "                   n_estimators=1000,subsample=1,\n",
    "                   max_depth=15,n_jobs=3)#binary:logistic\n",
    "\n",
    "xgb.fit(Train_Features, Train_Target.ravel(),eval_metric=eval_metric, eval_set=eval_set,verbose=False,early_stopping_rounds=50)\n",
    "\n",
    "preds_xgb = xgb.predict(Test_Features)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_curve,auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, xgb.predict_proba(Test_Features)[:,1])\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1\n",
      "0  101   4\n",
      "1   33  65\n",
      "True Positives: 65\n",
      "True Negatives: 101\n",
      "False Positives: 4\n",
      "False Negatives: 33\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.82\n",
      "Mis-Classification: 0.18\n",
      "Sensitivity: 0.66\n",
      "Specificity: 0.96\n",
      "Precision: 0.96\n",
      "f_1 Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,preds_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestXGBoostmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump((xgb), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestRFmodel/bestRFmodel.pickle\", \"rb\") as f:\n",
    "    rfa = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AliHaidar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9102526724975704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=6, n_estimators=200)\n",
    "rf.fit(Train_Features, Train_Target)\n",
    "preds_rf = rf.predict(Test_Features)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, rf.predict_proba(Test_Features)[:,1])\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  89  16\n",
      "1  18  80\n",
      "True Positives: 80\n",
      "True Negatives: 89\n",
      "False Positives: 16\n",
      "False Negatives: 18\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.83\n",
      "Mis-Classification: 0.17\n",
      "Sensitivity: 0.82\n",
      "Specificity: 0.85\n",
      "Precision: 0.85\n",
      "f_1 Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_rf = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664,)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9015549076773567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n",
    "bdt = BaggingClassifier(n_estimators=200,base_estimator=clf).fit(Train_Features, Train_Target)\n",
    "#Predict the response for test dataset\n",
    "preds_bdt = bdt.predict(Test_Features)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, bdt.predict_proba(Test_Features)[:,1])\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  86  19\n",
      "1  11  87\n",
      "True Positives: 87\n",
      "True Negatives: 86\n",
      "False Positives: 19\n",
      "False Negatives: 11\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.85\n",
      "Mis-Classification: 0.15\n",
      "Sensitivity: 0.89\n",
      "Specificity: 0.82\n",
      "Precision: 0.82\n",
      "f_1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,preds_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestbdtmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump((bdt), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8350826044703596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=200)\n",
    "clf.fit(Train_Features,Train_Target)\n",
    "#Predict the response for test dataset\n",
    "preds_adaboost = clf.predict(Test_Features)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, clf.predict_proba(Test_Features)[:,1])\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  84  21\n",
      "1  36  62\n",
      "True Positives: 62\n",
      "True Negatives: 84\n",
      "False Positives: 21\n",
      "False Negatives: 36\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.72\n",
      "Mis-Classification: 0.28\n",
      "Sensitivity: 0.63\n",
      "Specificity: 0.8\n",
      "Precision: 0.8\n",
      "f_1 Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,preds_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestadaboostmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump((clf), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's xentropy: 0.680922\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's xentropy: 0.662609\n",
      "[3]\tvalid_0's xentropy: 0.638034\n",
      "[4]\tvalid_0's xentropy: 0.635319\n",
      "[5]\tvalid_0's xentropy: 0.622174\n",
      "[6]\tvalid_0's xentropy: 0.614138\n",
      "[7]\tvalid_0's xentropy: 0.607836\n",
      "[8]\tvalid_0's xentropy: 0.603123\n",
      "[9]\tvalid_0's xentropy: 0.591247\n",
      "[10]\tvalid_0's xentropy: 0.589585\n",
      "[11]\tvalid_0's xentropy: 0.585327\n",
      "[12]\tvalid_0's xentropy: 0.578837\n",
      "[13]\tvalid_0's xentropy: 0.57855\n",
      "[14]\tvalid_0's xentropy: 0.581009\n",
      "[15]\tvalid_0's xentropy: 0.576708\n",
      "[16]\tvalid_0's xentropy: 0.575278\n",
      "[17]\tvalid_0's xentropy: 0.573405\n",
      "[18]\tvalid_0's xentropy: 0.573272\n",
      "[19]\tvalid_0's xentropy: 0.572891\n",
      "[20]\tvalid_0's xentropy: 0.575715\n",
      "[21]\tvalid_0's xentropy: 0.573019\n",
      "[22]\tvalid_0's xentropy: 0.576273\n",
      "[23]\tvalid_0's xentropy: 0.576701\n",
      "[24]\tvalid_0's xentropy: 0.569728\n",
      "[25]\tvalid_0's xentropy: 0.569666\n",
      "[26]\tvalid_0's xentropy: 0.567626\n",
      "[27]\tvalid_0's xentropy: 0.568559\n",
      "[28]\tvalid_0's xentropy: 0.570393\n",
      "[29]\tvalid_0's xentropy: 0.567488\n",
      "[30]\tvalid_0's xentropy: 0.568803\n",
      "[31]\tvalid_0's xentropy: 0.572498\n",
      "[32]\tvalid_0's xentropy: 0.571299\n",
      "[33]\tvalid_0's xentropy: 0.57315\n",
      "[34]\tvalid_0's xentropy: 0.57601\n",
      "[35]\tvalid_0's xentropy: 0.579305\n",
      "[36]\tvalid_0's xentropy: 0.577826\n",
      "[37]\tvalid_0's xentropy: 0.570137\n",
      "[38]\tvalid_0's xentropy: 0.574907\n",
      "[39]\tvalid_0's xentropy: 0.573075\n",
      "[40]\tvalid_0's xentropy: 0.571177\n",
      "[41]\tvalid_0's xentropy: 0.577407\n",
      "[42]\tvalid_0's xentropy: 0.579436\n",
      "[43]\tvalid_0's xentropy: 0.58152\n",
      "[44]\tvalid_0's xentropy: 0.584455\n",
      "[45]\tvalid_0's xentropy: 0.585025\n",
      "[46]\tvalid_0's xentropy: 0.587965\n",
      "[47]\tvalid_0's xentropy: 0.590276\n",
      "[48]\tvalid_0's xentropy: 0.587938\n",
      "[49]\tvalid_0's xentropy: 0.591986\n",
      "[50]\tvalid_0's xentropy: 0.594327\n",
      "[51]\tvalid_0's xentropy: 0.59588\n",
      "[52]\tvalid_0's xentropy: 0.597933\n",
      "[53]\tvalid_0's xentropy: 0.600693\n",
      "[54]\tvalid_0's xentropy: 0.602103\n",
      "[55]\tvalid_0's xentropy: 0.601005\n",
      "[56]\tvalid_0's xentropy: 0.60166\n",
      "[57]\tvalid_0's xentropy: 0.607182\n",
      "[58]\tvalid_0's xentropy: 0.610554\n",
      "[59]\tvalid_0's xentropy: 0.608384\n",
      "[60]\tvalid_0's xentropy: 0.613204\n",
      "[61]\tvalid_0's xentropy: 0.617673\n",
      "[62]\tvalid_0's xentropy: 0.626622\n",
      "[63]\tvalid_0's xentropy: 0.628656\n",
      "[64]\tvalid_0's xentropy: 0.629411\n",
      "[65]\tvalid_0's xentropy: 0.630284\n",
      "[66]\tvalid_0's xentropy: 0.639286\n",
      "[67]\tvalid_0's xentropy: 0.642686\n",
      "[68]\tvalid_0's xentropy: 0.650949\n",
      "[69]\tvalid_0's xentropy: 0.654579\n",
      "[70]\tvalid_0's xentropy: 0.664776\n",
      "[71]\tvalid_0's xentropy: 0.675673\n",
      "[72]\tvalid_0's xentropy: 0.682808\n",
      "[73]\tvalid_0's xentropy: 0.682725\n",
      "[74]\tvalid_0's xentropy: 0.683921\n",
      "[75]\tvalid_0's xentropy: 0.685866\n",
      "[76]\tvalid_0's xentropy: 0.688883\n",
      "[77]\tvalid_0's xentropy: 0.689385\n",
      "[78]\tvalid_0's xentropy: 0.694878\n",
      "[79]\tvalid_0's xentropy: 0.697299\n",
      "[80]\tvalid_0's xentropy: 0.702828\n",
      "[81]\tvalid_0's xentropy: 0.706079\n",
      "[82]\tvalid_0's xentropy: 0.711581\n",
      "[83]\tvalid_0's xentropy: 0.714243\n",
      "[84]\tvalid_0's xentropy: 0.715505\n",
      "[85]\tvalid_0's xentropy: 0.718466\n",
      "[86]\tvalid_0's xentropy: 0.721076\n",
      "[87]\tvalid_0's xentropy: 0.72466\n",
      "[88]\tvalid_0's xentropy: 0.732164\n",
      "[89]\tvalid_0's xentropy: 0.738936\n",
      "[90]\tvalid_0's xentropy: 0.741343\n",
      "[91]\tvalid_0's xentropy: 0.737979\n",
      "[92]\tvalid_0's xentropy: 0.737345\n",
      "[93]\tvalid_0's xentropy: 0.742934\n",
      "[94]\tvalid_0's xentropy: 0.744408\n",
      "[95]\tvalid_0's xentropy: 0.750817\n",
      "[96]\tvalid_0's xentropy: 0.763049\n",
      "[97]\tvalid_0's xentropy: 0.763455\n",
      "[98]\tvalid_0's xentropy: 0.764737\n",
      "[99]\tvalid_0's xentropy: 0.769841\n",
      "[100]\tvalid_0's xentropy: 0.772086\n",
      "[101]\tvalid_0's xentropy: 0.774694\n",
      "[102]\tvalid_0's xentropy: 0.778615\n",
      "[103]\tvalid_0's xentropy: 0.780271\n",
      "[104]\tvalid_0's xentropy: 0.777508\n",
      "[105]\tvalid_0's xentropy: 0.775689\n",
      "[106]\tvalid_0's xentropy: 0.783912\n",
      "[107]\tvalid_0's xentropy: 0.788209\n",
      "[108]\tvalid_0's xentropy: 0.788601\n",
      "[109]\tvalid_0's xentropy: 0.791357\n",
      "[110]\tvalid_0's xentropy: 0.792444\n",
      "[111]\tvalid_0's xentropy: 0.796865\n",
      "[112]\tvalid_0's xentropy: 0.807927\n",
      "[113]\tvalid_0's xentropy: 0.810272\n",
      "[114]\tvalid_0's xentropy: 0.814678\n",
      "[115]\tvalid_0's xentropy: 0.822929\n",
      "[116]\tvalid_0's xentropy: 0.838264\n",
      "[117]\tvalid_0's xentropy: 0.845306\n",
      "[118]\tvalid_0's xentropy: 0.847164\n",
      "[119]\tvalid_0's xentropy: 0.848434\n",
      "[120]\tvalid_0's xentropy: 0.853324\n",
      "[121]\tvalid_0's xentropy: 0.85725\n",
      "[122]\tvalid_0's xentropy: 0.862583\n",
      "[123]\tvalid_0's xentropy: 0.870479\n",
      "[124]\tvalid_0's xentropy: 0.869736\n",
      "[125]\tvalid_0's xentropy: 0.875257\n",
      "[126]\tvalid_0's xentropy: 0.880234\n",
      "[127]\tvalid_0's xentropy: 0.884319\n",
      "[128]\tvalid_0's xentropy: 0.889279\n",
      "[129]\tvalid_0's xentropy: 0.887668\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's xentropy: 0.567488\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "train_data = lightgbm.Dataset(Train_Features, label=np.squeeze(Train_Target))\n",
    "val_data = lightgbm.Dataset(Val_Features, label=np.squeeze(Val_Target))\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'cross_entropy',\n",
    "    'boosting': 'gbdt',#'gbdt' 'dart'\n",
    "    'num_leaves': 21,\n",
    "    'feature_fraction': 0.99,\n",
    "    'bagging_fraction': 0.99,\n",
    "    'bagging_freq': 30,  'learning_rate': 0.1,\n",
    "    'verbose': 2,\n",
    "}\n",
    "\n",
    "gbm = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=val_data,\n",
    "                       num_boost_round=1000,\n",
    "                       early_stopping_rounds=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9023323615160349\n"
     ]
    }
   ],
   "source": [
    "preds_gbdt=gbm.predict(Test_Features)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, preds_gbdt)\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  90  15\n",
      "1  18  80\n",
      "True Positives: 80\n",
      "True Negatives: 90\n",
      "False Positives: 15\n",
      "False Negatives: 18\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.84\n",
      "Mis-Classification: 0.16\n",
      "Sensitivity: 0.82\n",
      "Specificity: 0.86\n",
      "Precision: 0.86\n",
      "f_1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,np.round(preds_gbdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestlightgbmmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump((gbm), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.681957\n",
      "[2]\tvalid_0's binary_logloss: 0.671843\n",
      "[3]\tvalid_0's binary_logloss: 0.651553\n",
      "[4]\tvalid_0's binary_logloss: 0.635626\n",
      "[5]\tvalid_0's binary_logloss: 0.620932\n",
      "[6]\tvalid_0's binary_logloss: 0.6112\n",
      "[7]\tvalid_0's binary_logloss: 0.601755\n",
      "[8]\tvalid_0's binary_logloss: 0.602437\n",
      "[9]\tvalid_0's binary_logloss: 0.591426\n",
      "[10]\tvalid_0's binary_logloss: 0.582238\n",
      "[11]\tvalid_0's binary_logloss: 0.565282\n",
      "[12]\tvalid_0's binary_logloss: 0.570528\n",
      "[13]\tvalid_0's binary_logloss: 0.561578\n",
      "[14]\tvalid_0's binary_logloss: 0.559752\n",
      "[15]\tvalid_0's binary_logloss: 0.560612\n",
      "[16]\tvalid_0's binary_logloss: 0.557724\n",
      "[17]\tvalid_0's binary_logloss: 0.560193\n",
      "[18]\tvalid_0's binary_logloss: 0.560525\n",
      "[19]\tvalid_0's binary_logloss: 0.556087\n",
      "[20]\tvalid_0's binary_logloss: 0.552506\n",
      "[21]\tvalid_0's binary_logloss: 0.554106\n",
      "[22]\tvalid_0's binary_logloss: 0.556701\n",
      "[23]\tvalid_0's binary_logloss: 0.550505\n",
      "[24]\tvalid_0's binary_logloss: 0.557925\n",
      "[25]\tvalid_0's binary_logloss: 0.558272\n",
      "[26]\tvalid_0's binary_logloss: 0.560748\n",
      "[27]\tvalid_0's binary_logloss: 0.564916\n",
      "[28]\tvalid_0's binary_logloss: 0.564447\n",
      "[29]\tvalid_0's binary_logloss: 0.566663\n",
      "[30]\tvalid_0's binary_logloss: 0.566423\n",
      "[31]\tvalid_0's binary_logloss: 0.568727\n",
      "[32]\tvalid_0's binary_logloss: 0.577032\n",
      "[33]\tvalid_0's binary_logloss: 0.578923\n",
      "[34]\tvalid_0's binary_logloss: 0.583674\n",
      "[35]\tvalid_0's binary_logloss: 0.580631\n",
      "[36]\tvalid_0's binary_logloss: 0.580175\n",
      "[37]\tvalid_0's binary_logloss: 0.579242\n",
      "[38]\tvalid_0's binary_logloss: 0.581971\n",
      "[39]\tvalid_0's binary_logloss: 0.58342\n",
      "[40]\tvalid_0's binary_logloss: 0.584597\n",
      "[41]\tvalid_0's binary_logloss: 0.583908\n",
      "[42]\tvalid_0's binary_logloss: 0.589817\n",
      "[43]\tvalid_0's binary_logloss: 0.58938\n",
      "[44]\tvalid_0's binary_logloss: 0.589661\n",
      "[45]\tvalid_0's binary_logloss: 0.591028\n",
      "[46]\tvalid_0's binary_logloss: 0.589453\n",
      "[47]\tvalid_0's binary_logloss: 0.602634\n",
      "[48]\tvalid_0's binary_logloss: 0.599492\n",
      "[49]\tvalid_0's binary_logloss: 0.596527\n",
      "[50]\tvalid_0's binary_logloss: 0.594199\n",
      "[51]\tvalid_0's binary_logloss: 0.6003\n",
      "[52]\tvalid_0's binary_logloss: 0.601636\n",
      "[53]\tvalid_0's binary_logloss: 0.599803\n",
      "[54]\tvalid_0's binary_logloss: 0.602053\n",
      "[55]\tvalid_0's binary_logloss: 0.603035\n",
      "[56]\tvalid_0's binary_logloss: 0.601476\n",
      "[57]\tvalid_0's binary_logloss: 0.604218\n",
      "[58]\tvalid_0's binary_logloss: 0.603883\n",
      "[59]\tvalid_0's binary_logloss: 0.602587\n",
      "[60]\tvalid_0's binary_logloss: 0.605054\n",
      "[61]\tvalid_0's binary_logloss: 0.603847\n",
      "[62]\tvalid_0's binary_logloss: 0.603108\n",
      "[63]\tvalid_0's binary_logloss: 0.601269\n",
      "[64]\tvalid_0's binary_logloss: 0.596104\n",
      "[65]\tvalid_0's binary_logloss: 0.595134\n",
      "[66]\tvalid_0's binary_logloss: 0.598477\n",
      "[67]\tvalid_0's binary_logloss: 0.604199\n",
      "[68]\tvalid_0's binary_logloss: 0.605887\n",
      "[69]\tvalid_0's binary_logloss: 0.602593\n",
      "[70]\tvalid_0's binary_logloss: 0.599885\n",
      "[71]\tvalid_0's binary_logloss: 0.601013\n",
      "[72]\tvalid_0's binary_logloss: 0.612695\n",
      "[73]\tvalid_0's binary_logloss: 0.61866\n",
      "[74]\tvalid_0's binary_logloss: 0.61593\n",
      "[75]\tvalid_0's binary_logloss: 0.619746\n",
      "[76]\tvalid_0's binary_logloss: 0.615185\n",
      "[77]\tvalid_0's binary_logloss: 0.614256\n",
      "[78]\tvalid_0's binary_logloss: 0.612737\n",
      "[79]\tvalid_0's binary_logloss: 0.617506\n",
      "[80]\tvalid_0's binary_logloss: 0.617815\n",
      "[81]\tvalid_0's binary_logloss: 0.616964\n",
      "[82]\tvalid_0's binary_logloss: 0.613886\n",
      "[83]\tvalid_0's binary_logloss: 0.611913\n",
      "[84]\tvalid_0's binary_logloss: 0.610434\n",
      "[85]\tvalid_0's binary_logloss: 0.609465\n",
      "[86]\tvalid_0's binary_logloss: 0.616744\n",
      "[87]\tvalid_0's binary_logloss: 0.621427\n",
      "[88]\tvalid_0's binary_logloss: 0.618423\n",
      "[89]\tvalid_0's binary_logloss: 0.616742\n",
      "[90]\tvalid_0's binary_logloss: 0.614128\n",
      "[91]\tvalid_0's binary_logloss: 0.612267\n",
      "[92]\tvalid_0's binary_logloss: 0.614525\n",
      "[93]\tvalid_0's binary_logloss: 0.621558\n",
      "[94]\tvalid_0's binary_logloss: 0.618731\n",
      "[95]\tvalid_0's binary_logloss: 0.617564\n",
      "[96]\tvalid_0's binary_logloss: 0.615319\n",
      "[97]\tvalid_0's binary_logloss: 0.621455\n",
      "[98]\tvalid_0's binary_logloss: 0.620518\n",
      "[99]\tvalid_0's binary_logloss: 0.625942\n",
      "[100]\tvalid_0's binary_logloss: 0.621072\n",
      "[101]\tvalid_0's binary_logloss: 0.618625\n",
      "[102]\tvalid_0's binary_logloss: 0.615277\n",
      "[103]\tvalid_0's binary_logloss: 0.61347\n",
      "[104]\tvalid_0's binary_logloss: 0.614541\n",
      "[105]\tvalid_0's binary_logloss: 0.612314\n",
      "[106]\tvalid_0's binary_logloss: 0.610818\n",
      "[107]\tvalid_0's binary_logloss: 0.608742\n",
      "[108]\tvalid_0's binary_logloss: 0.607312\n",
      "[109]\tvalid_0's binary_logloss: 0.606814\n",
      "[110]\tvalid_0's binary_logloss: 0.604889\n",
      "[111]\tvalid_0's binary_logloss: 0.609766\n",
      "[112]\tvalid_0's binary_logloss: 0.613883\n",
      "[113]\tvalid_0's binary_logloss: 0.616233\n",
      "[114]\tvalid_0's binary_logloss: 0.614443\n",
      "[115]\tvalid_0's binary_logloss: 0.61955\n",
      "[116]\tvalid_0's binary_logloss: 0.624913\n",
      "[117]\tvalid_0's binary_logloss: 0.622381\n",
      "[118]\tvalid_0's binary_logloss: 0.624868\n",
      "[119]\tvalid_0's binary_logloss: 0.62276\n",
      "[120]\tvalid_0's binary_logloss: 0.620991\n",
      "[121]\tvalid_0's binary_logloss: 0.616846\n",
      "[122]\tvalid_0's binary_logloss: 0.614226\n",
      "[123]\tvalid_0's binary_logloss: 0.605777\n",
      "[124]\tvalid_0's binary_logloss: 0.601974\n",
      "[125]\tvalid_0's binary_logloss: 0.599088\n",
      "[126]\tvalid_0's binary_logloss: 0.598127\n",
      "[127]\tvalid_0's binary_logloss: 0.596893\n",
      "[128]\tvalid_0's binary_logloss: 0.595574\n",
      "[129]\tvalid_0's binary_logloss: 0.596188\n",
      "[130]\tvalid_0's binary_logloss: 0.600436\n",
      "[131]\tvalid_0's binary_logloss: 0.599739\n",
      "[132]\tvalid_0's binary_logloss: 0.595359\n",
      "[133]\tvalid_0's binary_logloss: 0.596832\n",
      "[134]\tvalid_0's binary_logloss: 0.596434\n",
      "[135]\tvalid_0's binary_logloss: 0.597543\n",
      "[136]\tvalid_0's binary_logloss: 0.596802\n",
      "[137]\tvalid_0's binary_logloss: 0.596066\n",
      "[138]\tvalid_0's binary_logloss: 0.597222\n",
      "[139]\tvalid_0's binary_logloss: 0.599974\n",
      "[140]\tvalid_0's binary_logloss: 0.599083\n",
      "[141]\tvalid_0's binary_logloss: 0.597172\n",
      "[142]\tvalid_0's binary_logloss: 0.595059\n",
      "[143]\tvalid_0's binary_logloss: 0.594318\n",
      "[144]\tvalid_0's binary_logloss: 0.593214\n",
      "[145]\tvalid_0's binary_logloss: 0.594979\n",
      "[146]\tvalid_0's binary_logloss: 0.594086\n",
      "[147]\tvalid_0's binary_logloss: 0.592496\n",
      "[148]\tvalid_0's binary_logloss: 0.592321\n",
      "[149]\tvalid_0's binary_logloss: 0.592312\n",
      "[150]\tvalid_0's binary_logloss: 0.594908\n",
      "[151]\tvalid_0's binary_logloss: 0.593597\n",
      "[152]\tvalid_0's binary_logloss: 0.592607\n",
      "[153]\tvalid_0's binary_logloss: 0.58886\n",
      "[154]\tvalid_0's binary_logloss: 0.588145\n",
      "[155]\tvalid_0's binary_logloss: 0.591795\n",
      "[156]\tvalid_0's binary_logloss: 0.590479\n",
      "[157]\tvalid_0's binary_logloss: 0.589494\n",
      "[158]\tvalid_0's binary_logloss: 0.588654\n",
      "[159]\tvalid_0's binary_logloss: 0.587156\n",
      "[160]\tvalid_0's binary_logloss: 0.585765\n",
      "[161]\tvalid_0's binary_logloss: 0.590545\n",
      "[162]\tvalid_0's binary_logloss: 0.588871\n",
      "[163]\tvalid_0's binary_logloss: 0.589268\n",
      "[164]\tvalid_0's binary_logloss: 0.588933\n",
      "[165]\tvalid_0's binary_logloss: 0.58686\n",
      "[166]\tvalid_0's binary_logloss: 0.592504\n",
      "[167]\tvalid_0's binary_logloss: 0.591022\n",
      "[168]\tvalid_0's binary_logloss: 0.595037\n",
      "[169]\tvalid_0's binary_logloss: 0.600915\n",
      "[170]\tvalid_0's binary_logloss: 0.599733\n",
      "[171]\tvalid_0's binary_logloss: 0.608841\n",
      "[172]\tvalid_0's binary_logloss: 0.606717\n",
      "[173]\tvalid_0's binary_logloss: 0.606781\n",
      "[174]\tvalid_0's binary_logloss: 0.608105\n",
      "[175]\tvalid_0's binary_logloss: 0.609423\n",
      "[176]\tvalid_0's binary_logloss: 0.60828\n",
      "[177]\tvalid_0's binary_logloss: 0.606719\n",
      "[178]\tvalid_0's binary_logloss: 0.605054\n",
      "[179]\tvalid_0's binary_logloss: 0.612222\n",
      "[180]\tvalid_0's binary_logloss: 0.610431\n",
      "[181]\tvalid_0's binary_logloss: 0.614775\n",
      "[182]\tvalid_0's binary_logloss: 0.619283\n",
      "[183]\tvalid_0's binary_logloss: 0.620502\n",
      "[184]\tvalid_0's binary_logloss: 0.622169\n",
      "[185]\tvalid_0's binary_logloss: 0.620522\n",
      "[186]\tvalid_0's binary_logloss: 0.624097\n",
      "[187]\tvalid_0's binary_logloss: 0.623939\n",
      "[188]\tvalid_0's binary_logloss: 0.622876\n",
      "[189]\tvalid_0's binary_logloss: 0.620745\n",
      "[190]\tvalid_0's binary_logloss: 0.61873\n",
      "[191]\tvalid_0's binary_logloss: 0.620053\n",
      "[192]\tvalid_0's binary_logloss: 0.624083\n",
      "[193]\tvalid_0's binary_logloss: 0.630561\n",
      "[194]\tvalid_0's binary_logloss: 0.628815\n",
      "[195]\tvalid_0's binary_logloss: 0.626637\n",
      "[196]\tvalid_0's binary_logloss: 0.624166\n",
      "[197]\tvalid_0's binary_logloss: 0.622191\n",
      "[198]\tvalid_0's binary_logloss: 0.620107\n",
      "[199]\tvalid_0's binary_logloss: 0.616521\n",
      "[200]\tvalid_0's binary_logloss: 0.61502\n",
      "[201]\tvalid_0's binary_logloss: 0.613725\n",
      "[202]\tvalid_0's binary_logloss: 0.611791\n",
      "[203]\tvalid_0's binary_logloss: 0.613895\n",
      "[204]\tvalid_0's binary_logloss: 0.612326\n",
      "[205]\tvalid_0's binary_logloss: 0.610756\n",
      "[206]\tvalid_0's binary_logloss: 0.614047\n",
      "[207]\tvalid_0's binary_logloss: 0.612245\n",
      "[208]\tvalid_0's binary_logloss: 0.618659\n",
      "[209]\tvalid_0's binary_logloss: 0.617188\n",
      "[210]\tvalid_0's binary_logloss: 0.615514\n",
      "[211]\tvalid_0's binary_logloss: 0.613751\n",
      "[212]\tvalid_0's binary_logloss: 0.622319\n",
      "[213]\tvalid_0's binary_logloss: 0.627337\n",
      "[214]\tvalid_0's binary_logloss: 0.628948\n",
      "[215]\tvalid_0's binary_logloss: 0.635325\n",
      "[216]\tvalid_0's binary_logloss: 0.633201\n",
      "[217]\tvalid_0's binary_logloss: 0.63507\n",
      "[218]\tvalid_0's binary_logloss: 0.632001\n",
      "[219]\tvalid_0's binary_logloss: 0.630212\n",
      "[220]\tvalid_0's binary_logloss: 0.630443\n",
      "[221]\tvalid_0's binary_logloss: 0.628373\n",
      "[222]\tvalid_0's binary_logloss: 0.635038\n",
      "[223]\tvalid_0's binary_logloss: 0.63963\n",
      "[224]\tvalid_0's binary_logloss: 0.638606\n",
      "[225]\tvalid_0's binary_logloss: 0.636732\n",
      "[226]\tvalid_0's binary_logloss: 0.634792\n",
      "[227]\tvalid_0's binary_logloss: 0.633979\n",
      "[228]\tvalid_0's binary_logloss: 0.63771\n",
      "[229]\tvalid_0's binary_logloss: 0.636448\n",
      "[230]\tvalid_0's binary_logloss: 0.643707\n",
      "[231]\tvalid_0's binary_logloss: 0.643572\n",
      "[232]\tvalid_0's binary_logloss: 0.642287\n",
      "[233]\tvalid_0's binary_logloss: 0.640375\n",
      "[234]\tvalid_0's binary_logloss: 0.638182\n",
      "[235]\tvalid_0's binary_logloss: 0.636969\n",
      "[236]\tvalid_0's binary_logloss: 0.642028\n",
      "[237]\tvalid_0's binary_logloss: 0.645037\n",
      "[238]\tvalid_0's binary_logloss: 0.654456\n",
      "[239]\tvalid_0's binary_logloss: 0.65336\n",
      "[240]\tvalid_0's binary_logloss: 0.656971\n",
      "[241]\tvalid_0's binary_logloss: 0.654571\n",
      "[242]\tvalid_0's binary_logloss: 0.655874\n",
      "[243]\tvalid_0's binary_logloss: 0.654079\n",
      "[244]\tvalid_0's binary_logloss: 0.652037\n",
      "[245]\tvalid_0's binary_logloss: 0.652418\n",
      "[246]\tvalid_0's binary_logloss: 0.656727\n",
      "[247]\tvalid_0's binary_logloss: 0.662196\n",
      "[248]\tvalid_0's binary_logloss: 0.660075\n",
      "[249]\tvalid_0's binary_logloss: 0.658499\n",
      "[250]\tvalid_0's binary_logloss: 0.664181\n",
      "[251]\tvalid_0's binary_logloss: 0.66247\n",
      "[252]\tvalid_0's binary_logloss: 0.660279\n",
      "[253]\tvalid_0's binary_logloss: 0.664514\n",
      "[254]\tvalid_0's binary_logloss: 0.668026\n",
      "[255]\tvalid_0's binary_logloss: 0.672139\n",
      "[256]\tvalid_0's binary_logloss: 0.670899\n",
      "[257]\tvalid_0's binary_logloss: 0.673746\n",
      "[258]\tvalid_0's binary_logloss: 0.681653\n",
      "[259]\tvalid_0's binary_logloss: 0.679711\n",
      "[260]\tvalid_0's binary_logloss: 0.676954\n",
      "[261]\tvalid_0's binary_logloss: 0.675222\n",
      "[262]\tvalid_0's binary_logloss: 0.680856\n",
      "[263]\tvalid_0's binary_logloss: 0.680863\n",
      "[264]\tvalid_0's binary_logloss: 0.678535\n",
      "[265]\tvalid_0's binary_logloss: 0.681835\n",
      "[266]\tvalid_0's binary_logloss: 0.680312\n",
      "[267]\tvalid_0's binary_logloss: 0.679086\n",
      "[268]\tvalid_0's binary_logloss: 0.682045\n",
      "[269]\tvalid_0's binary_logloss: 0.680338\n",
      "[270]\tvalid_0's binary_logloss: 0.683265\n",
      "[271]\tvalid_0's binary_logloss: 0.681137\n",
      "[272]\tvalid_0's binary_logloss: 0.687503\n",
      "[273]\tvalid_0's binary_logloss: 0.689554\n",
      "[274]\tvalid_0's binary_logloss: 0.687674\n",
      "[275]\tvalid_0's binary_logloss: 0.694867\n",
      "[276]\tvalid_0's binary_logloss: 0.692312\n",
      "[277]\tvalid_0's binary_logloss: 0.701664\n",
      "[278]\tvalid_0's binary_logloss: 0.699503\n",
      "[279]\tvalid_0's binary_logloss: 0.707469\n",
      "[280]\tvalid_0's binary_logloss: 0.704862\n",
      "[281]\tvalid_0's binary_logloss: 0.702311\n",
      "[282]\tvalid_0's binary_logloss: 0.707415\n",
      "[283]\tvalid_0's binary_logloss: 0.70525\n",
      "[284]\tvalid_0's binary_logloss: 0.714619\n",
      "[285]\tvalid_0's binary_logloss: 0.720767\n",
      "[286]\tvalid_0's binary_logloss: 0.730363\n",
      "[287]\tvalid_0's binary_logloss: 0.734931\n",
      "[288]\tvalid_0's binary_logloss: 0.732386\n",
      "[289]\tvalid_0's binary_logloss: 0.73483\n",
      "[290]\tvalid_0's binary_logloss: 0.739516\n",
      "[291]\tvalid_0's binary_logloss: 0.740148\n",
      "[292]\tvalid_0's binary_logloss: 0.736512\n",
      "[293]\tvalid_0's binary_logloss: 0.733421\n",
      "[294]\tvalid_0's binary_logloss: 0.743363\n",
      "[295]\tvalid_0's binary_logloss: 0.741036\n",
      "[296]\tvalid_0's binary_logloss: 0.737738\n",
      "[297]\tvalid_0's binary_logloss: 0.745252\n",
      "[298]\tvalid_0's binary_logloss: 0.743232\n",
      "[299]\tvalid_0's binary_logloss: 0.745709\n",
      "[300]\tvalid_0's binary_logloss: 0.743308\n",
      "[301]\tvalid_0's binary_logloss: 0.741121\n",
      "[302]\tvalid_0's binary_logloss: 0.739617\n",
      "[303]\tvalid_0's binary_logloss: 0.736971\n",
      "[304]\tvalid_0's binary_logloss: 0.734522\n",
      "[305]\tvalid_0's binary_logloss: 0.731407\n",
      "[306]\tvalid_0's binary_logloss: 0.728686\n",
      "[307]\tvalid_0's binary_logloss: 0.726382\n",
      "[308]\tvalid_0's binary_logloss: 0.728747\n",
      "[309]\tvalid_0's binary_logloss: 0.727389\n",
      "[310]\tvalid_0's binary_logloss: 0.735471\n",
      "[311]\tvalid_0's binary_logloss: 0.742029\n",
      "[312]\tvalid_0's binary_logloss: 0.739555\n",
      "[313]\tvalid_0's binary_logloss: 0.74413\n",
      "[314]\tvalid_0's binary_logloss: 0.741892\n",
      "[315]\tvalid_0's binary_logloss: 0.739757\n",
      "[316]\tvalid_0's binary_logloss: 0.748548\n",
      "[317]\tvalid_0's binary_logloss: 0.756621\n",
      "[318]\tvalid_0's binary_logloss: 0.76134\n",
      "[319]\tvalid_0's binary_logloss: 0.759399\n",
      "[320]\tvalid_0's binary_logloss: 0.7725\n",
      "[321]\tvalid_0's binary_logloss: 0.769864\n",
      "[322]\tvalid_0's binary_logloss: 0.772686\n",
      "[323]\tvalid_0's binary_logloss: 0.783616\n",
      "[324]\tvalid_0's binary_logloss: 0.780146\n",
      "[325]\tvalid_0's binary_logloss: 0.788957\n",
      "[326]\tvalid_0's binary_logloss: 0.786918\n",
      "[327]\tvalid_0's binary_logloss: 0.790999\n",
      "[328]\tvalid_0's binary_logloss: 0.78871\n",
      "[329]\tvalid_0's binary_logloss: 0.792064\n",
      "[330]\tvalid_0's binary_logloss: 0.788954\n",
      "[331]\tvalid_0's binary_logloss: 0.785768\n",
      "[332]\tvalid_0's binary_logloss: 0.783687\n",
      "[333]\tvalid_0's binary_logloss: 0.781178\n",
      "[334]\tvalid_0's binary_logloss: 0.778649\n",
      "[335]\tvalid_0's binary_logloss: 0.785642\n",
      "[336]\tvalid_0's binary_logloss: 0.782868\n",
      "[337]\tvalid_0's binary_logloss: 0.786394\n",
      "[338]\tvalid_0's binary_logloss: 0.791891\n",
      "[339]\tvalid_0's binary_logloss: 0.789068\n",
      "[340]\tvalid_0's binary_logloss: 0.785923\n",
      "[341]\tvalid_0's binary_logloss: 0.788054\n",
      "[342]\tvalid_0's binary_logloss: 0.791934\n",
      "[343]\tvalid_0's binary_logloss: 0.793395\n",
      "[344]\tvalid_0's binary_logloss: 0.791675\n",
      "[345]\tvalid_0's binary_logloss: 0.795545\n",
      "[346]\tvalid_0's binary_logloss: 0.803788\n",
      "[347]\tvalid_0's binary_logloss: 0.801664\n",
      "[348]\tvalid_0's binary_logloss: 0.810164\n",
      "[349]\tvalid_0's binary_logloss: 0.81576\n",
      "[350]\tvalid_0's binary_logloss: 0.812549\n",
      "[351]\tvalid_0's binary_logloss: 0.817681\n",
      "[352]\tvalid_0's binary_logloss: 0.820169\n",
      "[353]\tvalid_0's binary_logloss: 0.820154\n",
      "[354]\tvalid_0's binary_logloss: 0.818832\n",
      "[355]\tvalid_0's binary_logloss: 0.816096\n",
      "[356]\tvalid_0's binary_logloss: 0.825975\n",
      "[357]\tvalid_0's binary_logloss: 0.823711\n",
      "[358]\tvalid_0's binary_logloss: 0.827109\n",
      "[359]\tvalid_0's binary_logloss: 0.824164\n",
      "[360]\tvalid_0's binary_logloss: 0.825104\n",
      "[361]\tvalid_0's binary_logloss: 0.826822\n",
      "[362]\tvalid_0's binary_logloss: 0.832566\n",
      "[363]\tvalid_0's binary_logloss: 0.830278\n",
      "[364]\tvalid_0's binary_logloss: 0.82695\n",
      "[365]\tvalid_0's binary_logloss: 0.826472\n",
      "[366]\tvalid_0's binary_logloss: 0.824219\n",
      "[367]\tvalid_0's binary_logloss: 0.821191\n",
      "[368]\tvalid_0's binary_logloss: 0.826691\n",
      "[369]\tvalid_0's binary_logloss: 0.824835\n",
      "[370]\tvalid_0's binary_logloss: 0.83018\n",
      "[371]\tvalid_0's binary_logloss: 0.827812\n",
      "[372]\tvalid_0's binary_logloss: 0.833558\n",
      "[373]\tvalid_0's binary_logloss: 0.841971\n",
      "[374]\tvalid_0's binary_logloss: 0.847408\n",
      "[375]\tvalid_0's binary_logloss: 0.84692\n",
      "[376]\tvalid_0's binary_logloss: 0.844656\n",
      "[377]\tvalid_0's binary_logloss: 0.851316\n",
      "[378]\tvalid_0's binary_logloss: 0.847981\n",
      "[379]\tvalid_0's binary_logloss: 0.845695\n",
      "[380]\tvalid_0's binary_logloss: 0.848423\n",
      "[381]\tvalid_0's binary_logloss: 0.845248\n",
      "[382]\tvalid_0's binary_logloss: 0.842673\n",
      "[383]\tvalid_0's binary_logloss: 0.846048\n",
      "[384]\tvalid_0's binary_logloss: 0.848802\n",
      "[385]\tvalid_0's binary_logloss: 0.845301\n",
      "[386]\tvalid_0's binary_logloss: 0.85498\n",
      "[387]\tvalid_0's binary_logloss: 0.857726\n",
      "[388]\tvalid_0's binary_logloss: 0.86486\n",
      "[389]\tvalid_0's binary_logloss: 0.874605\n",
      "[390]\tvalid_0's binary_logloss: 0.872946\n",
      "[391]\tvalid_0's binary_logloss: 0.870084\n",
      "[392]\tvalid_0's binary_logloss: 0.871974\n",
      "[393]\tvalid_0's binary_logloss: 0.875757\n",
      "[394]\tvalid_0's binary_logloss: 0.884832\n",
      "[395]\tvalid_0's binary_logloss: 0.885012\n",
      "[396]\tvalid_0's binary_logloss: 0.881904\n",
      "[397]\tvalid_0's binary_logloss: 0.889456\n",
      "[398]\tvalid_0's binary_logloss: 0.893794\n",
      "[399]\tvalid_0's binary_logloss: 0.896284\n",
      "[400]\tvalid_0's binary_logloss: 0.903034\n",
      "[401]\tvalid_0's binary_logloss: 0.899762\n",
      "[402]\tvalid_0's binary_logloss: 0.907969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403]\tvalid_0's binary_logloss: 0.905057\n",
      "[404]\tvalid_0's binary_logloss: 0.909214\n",
      "[405]\tvalid_0's binary_logloss: 0.917771\n",
      "[406]\tvalid_0's binary_logloss: 0.915099\n",
      "[407]\tvalid_0's binary_logloss: 0.922397\n",
      "[408]\tvalid_0's binary_logloss: 0.919255\n",
      "[409]\tvalid_0's binary_logloss: 0.92567\n",
      "[410]\tvalid_0's binary_logloss: 0.932489\n",
      "[411]\tvalid_0's binary_logloss: 0.938688\n",
      "[412]\tvalid_0's binary_logloss: 0.935562\n",
      "[413]\tvalid_0's binary_logloss: 0.932205\n",
      "[414]\tvalid_0's binary_logloss: 0.94035\n",
      "[415]\tvalid_0's binary_logloss: 0.948593\n",
      "[416]\tvalid_0's binary_logloss: 0.955435\n",
      "[417]\tvalid_0's binary_logloss: 0.951389\n",
      "[418]\tvalid_0's binary_logloss: 0.947746\n",
      "[419]\tvalid_0's binary_logloss: 0.948102\n",
      "[420]\tvalid_0's binary_logloss: 0.944977\n",
      "[421]\tvalid_0's binary_logloss: 0.941573\n",
      "[422]\tvalid_0's binary_logloss: 0.942651\n",
      "[423]\tvalid_0's binary_logloss: 0.955305\n",
      "[424]\tvalid_0's binary_logloss: 0.963742\n",
      "[425]\tvalid_0's binary_logloss: 0.959851\n",
      "[426]\tvalid_0's binary_logloss: 0.963506\n",
      "[427]\tvalid_0's binary_logloss: 0.972196\n",
      "[428]\tvalid_0's binary_logloss: 0.969027\n",
      "[429]\tvalid_0's binary_logloss: 0.969074\n",
      "[430]\tvalid_0's binary_logloss: 0.966312\n",
      "[431]\tvalid_0's binary_logloss: 0.975139\n",
      "[432]\tvalid_0's binary_logloss: 0.982631\n",
      "[433]\tvalid_0's binary_logloss: 0.987012\n",
      "[434]\tvalid_0's binary_logloss: 0.984002\n",
      "[435]\tvalid_0's binary_logloss: 0.981202\n",
      "[436]\tvalid_0's binary_logloss: 0.982332\n",
      "[437]\tvalid_0's binary_logloss: 0.986577\n",
      "[438]\tvalid_0's binary_logloss: 0.983715\n",
      "[439]\tvalid_0's binary_logloss: 0.981273\n",
      "[440]\tvalid_0's binary_logloss: 0.98425\n",
      "[441]\tvalid_0's binary_logloss: 0.989153\n",
      "[442]\tvalid_0's binary_logloss: 0.995539\n",
      "[443]\tvalid_0's binary_logloss: 0.992204\n",
      "[444]\tvalid_0's binary_logloss: 1.0004\n",
      "[445]\tvalid_0's binary_logloss: 1.01038\n",
      "[446]\tvalid_0's binary_logloss: 1.0076\n",
      "[447]\tvalid_0's binary_logloss: 1.01053\n",
      "[448]\tvalid_0's binary_logloss: 1.01723\n",
      "[449]\tvalid_0's binary_logloss: 1.02211\n",
      "[450]\tvalid_0's binary_logloss: 1.02476\n",
      "[451]\tvalid_0's binary_logloss: 1.03213\n",
      "[452]\tvalid_0's binary_logloss: 1.02878\n",
      "[453]\tvalid_0's binary_logloss: 1.02577\n",
      "[454]\tvalid_0's binary_logloss: 1.02293\n",
      "[455]\tvalid_0's binary_logloss: 1.03113\n",
      "[456]\tvalid_0's binary_logloss: 1.02773\n",
      "[457]\tvalid_0's binary_logloss: 1.02431\n",
      "[458]\tvalid_0's binary_logloss: 1.03233\n",
      "[459]\tvalid_0's binary_logloss: 1.04439\n",
      "[460]\tvalid_0's binary_logloss: 1.04196\n",
      "[461]\tvalid_0's binary_logloss: 1.0427\n",
      "[462]\tvalid_0's binary_logloss: 1.03882\n",
      "[463]\tvalid_0's binary_logloss: 1.03539\n",
      "[464]\tvalid_0's binary_logloss: 1.04706\n",
      "[465]\tvalid_0's binary_logloss: 1.05274\n",
      "[466]\tvalid_0's binary_logloss: 1.04948\n",
      "[467]\tvalid_0's binary_logloss: 1.05474\n",
      "[468]\tvalid_0's binary_logloss: 1.05195\n",
      "[469]\tvalid_0's binary_logloss: 1.05232\n",
      "[470]\tvalid_0's binary_logloss: 1.04925\n",
      "[471]\tvalid_0's binary_logloss: 1.05207\n",
      "[472]\tvalid_0's binary_logloss: 1.04863\n",
      "[473]\tvalid_0's binary_logloss: 1.05325\n",
      "[474]\tvalid_0's binary_logloss: 1.05386\n",
      "[475]\tvalid_0's binary_logloss: 1.05756\n",
      "[476]\tvalid_0's binary_logloss: 1.05537\n",
      "[477]\tvalid_0's binary_logloss: 1.06051\n",
      "[478]\tvalid_0's binary_logloss: 1.05697\n",
      "[479]\tvalid_0's binary_logloss: 1.05407\n",
      "[480]\tvalid_0's binary_logloss: 1.05655\n",
      "[481]\tvalid_0's binary_logloss: 1.06006\n",
      "[482]\tvalid_0's binary_logloss: 1.05974\n",
      "[483]\tvalid_0's binary_logloss: 1.06066\n",
      "[484]\tvalid_0's binary_logloss: 1.06249\n",
      "[485]\tvalid_0's binary_logloss: 1.05977\n",
      "[486]\tvalid_0's binary_logloss: 1.05866\n",
      "[487]\tvalid_0's binary_logloss: 1.06262\n",
      "[488]\tvalid_0's binary_logloss: 1.06614\n",
      "[489]\tvalid_0's binary_logloss: 1.06919\n",
      "[490]\tvalid_0's binary_logloss: 1.06628\n",
      "[491]\tvalid_0's binary_logloss: 1.06366\n",
      "[492]\tvalid_0's binary_logloss: 1.06054\n",
      "[493]\tvalid_0's binary_logloss: 1.0578\n",
      "[494]\tvalid_0's binary_logloss: 1.05467\n",
      "[495]\tvalid_0's binary_logloss: 1.0605\n",
      "[496]\tvalid_0's binary_logloss: 1.06579\n",
      "[497]\tvalid_0's binary_logloss: 1.07279\n",
      "[498]\tvalid_0's binary_logloss: 1.07078\n",
      "[499]\tvalid_0's binary_logloss: 1.06774\n",
      "[500]\tvalid_0's binary_logloss: 1.07778\n",
      "[501]\tvalid_0's binary_logloss: 1.07473\n",
      "[502]\tvalid_0's binary_logloss: 1.07359\n",
      "[503]\tvalid_0's binary_logloss: 1.07497\n",
      "[504]\tvalid_0's binary_logloss: 1.07107\n",
      "[505]\tvalid_0's binary_logloss: 1.06852\n",
      "[506]\tvalid_0's binary_logloss: 1.0821\n",
      "[507]\tvalid_0's binary_logloss: 1.0866\n",
      "[508]\tvalid_0's binary_logloss: 1.08794\n",
      "[509]\tvalid_0's binary_logloss: 1.09351\n",
      "[510]\tvalid_0's binary_logloss: 1.09523\n",
      "[511]\tvalid_0's binary_logloss: 1.09196\n",
      "[512]\tvalid_0's binary_logloss: 1.08489\n",
      "[513]\tvalid_0's binary_logloss: 1.08234\n",
      "[514]\tvalid_0's binary_logloss: 1.08065\n",
      "[515]\tvalid_0's binary_logloss: 1.07686\n",
      "[516]\tvalid_0's binary_logloss: 1.07383\n",
      "[517]\tvalid_0's binary_logloss: 1.0707\n",
      "[518]\tvalid_0's binary_logloss: 1.06791\n",
      "[519]\tvalid_0's binary_logloss: 1.06513\n",
      "[520]\tvalid_0's binary_logloss: 1.06671\n",
      "[521]\tvalid_0's binary_logloss: 1.06544\n",
      "[522]\tvalid_0's binary_logloss: 1.06298\n",
      "[523]\tvalid_0's binary_logloss: 1.06032\n",
      "[524]\tvalid_0's binary_logloss: 1.05787\n",
      "[525]\tvalid_0's binary_logloss: 1.05529\n",
      "[526]\tvalid_0's binary_logloss: 1.06371\n",
      "[527]\tvalid_0's binary_logloss: 1.06101\n",
      "[528]\tvalid_0's binary_logloss: 1.06011\n",
      "[529]\tvalid_0's binary_logloss: 1.06633\n",
      "[530]\tvalid_0's binary_logloss: 1.0762\n",
      "[531]\tvalid_0's binary_logloss: 1.073\n",
      "[532]\tvalid_0's binary_logloss: 1.07527\n",
      "[533]\tvalid_0's binary_logloss: 1.0727\n",
      "[534]\tvalid_0's binary_logloss: 1.0767\n",
      "[535]\tvalid_0's binary_logloss: 1.07727\n",
      "[536]\tvalid_0's binary_logloss: 1.07516\n",
      "[537]\tvalid_0's binary_logloss: 1.07675\n",
      "[538]\tvalid_0's binary_logloss: 1.08049\n",
      "[539]\tvalid_0's binary_logloss: 1.07706\n",
      "[540]\tvalid_0's binary_logloss: 1.07431\n",
      "[541]\tvalid_0's binary_logloss: 1.0713\n",
      "[542]\tvalid_0's binary_logloss: 1.0761\n",
      "[543]\tvalid_0's binary_logloss: 1.07291\n",
      "[544]\tvalid_0's binary_logloss: 1.07034\n",
      "[545]\tvalid_0's binary_logloss: 1.06773\n",
      "[546]\tvalid_0's binary_logloss: 1.06819\n",
      "[547]\tvalid_0's binary_logloss: 1.07372\n",
      "[548]\tvalid_0's binary_logloss: 1.07136\n",
      "[549]\tvalid_0's binary_logloss: 1.06916\n",
      "[550]\tvalid_0's binary_logloss: 1.07779\n",
      "[551]\tvalid_0's binary_logloss: 1.08022\n",
      "[552]\tvalid_0's binary_logloss: 1.0862\n",
      "[553]\tvalid_0's binary_logloss: 1.08354\n",
      "[554]\tvalid_0's binary_logloss: 1.0809\n",
      "[555]\tvalid_0's binary_logloss: 1.08541\n",
      "[556]\tvalid_0's binary_logloss: 1.0823\n",
      "[557]\tvalid_0's binary_logloss: 1.07943\n",
      "[558]\tvalid_0's binary_logloss: 1.08228\n",
      "[559]\tvalid_0's binary_logloss: 1.08862\n",
      "[560]\tvalid_0's binary_logloss: 1.09599\n",
      "[561]\tvalid_0's binary_logloss: 1.09318\n",
      "[562]\tvalid_0's binary_logloss: 1.09094\n",
      "[563]\tvalid_0's binary_logloss: 1.08843\n",
      "[564]\tvalid_0's binary_logloss: 1.08624\n",
      "[565]\tvalid_0's binary_logloss: 1.08755\n",
      "[566]\tvalid_0's binary_logloss: 1.09394\n",
      "[567]\tvalid_0's binary_logloss: 1.09845\n",
      "[568]\tvalid_0's binary_logloss: 1.09585\n",
      "[569]\tvalid_0's binary_logloss: 1.09278\n",
      "[570]\tvalid_0's binary_logloss: 1.09002\n",
      "[571]\tvalid_0's binary_logloss: 1.08829\n",
      "[572]\tvalid_0's binary_logloss: 1.09229\n",
      "[573]\tvalid_0's binary_logloss: 1.08941\n",
      "[574]\tvalid_0's binary_logloss: 1.08737\n",
      "[575]\tvalid_0's binary_logloss: 1.088\n",
      "[576]\tvalid_0's binary_logloss: 1.08504\n",
      "[577]\tvalid_0's binary_logloss: 1.0821\n",
      "[578]\tvalid_0's binary_logloss: 1.07922\n",
      "[579]\tvalid_0's binary_logloss: 1.07669\n",
      "[580]\tvalid_0's binary_logloss: 1.07382\n",
      "[581]\tvalid_0's binary_logloss: 1.07731\n",
      "[582]\tvalid_0's binary_logloss: 1.07473\n",
      "[583]\tvalid_0's binary_logloss: 1.0757\n",
      "[584]\tvalid_0's binary_logloss: 1.07339\n",
      "[585]\tvalid_0's binary_logloss: 1.07862\n",
      "[586]\tvalid_0's binary_logloss: 1.07608\n",
      "[587]\tvalid_0's binary_logloss: 1.08478\n",
      "[588]\tvalid_0's binary_logloss: 1.08234\n",
      "[589]\tvalid_0's binary_logloss: 1.07965\n",
      "[590]\tvalid_0's binary_logloss: 1.07694\n",
      "[591]\tvalid_0's binary_logloss: 1.07389\n",
      "[592]\tvalid_0's binary_logloss: 1.07166\n",
      "[593]\tvalid_0's binary_logloss: 1.0742\n",
      "[594]\tvalid_0's binary_logloss: 1.07144\n",
      "[595]\tvalid_0's binary_logloss: 1.06902\n",
      "[596]\tvalid_0's binary_logloss: 1.0735\n",
      "[597]\tvalid_0's binary_logloss: 1.07107\n",
      "[598]\tvalid_0's binary_logloss: 1.06842\n",
      "[599]\tvalid_0's binary_logloss: 1.06979\n",
      "[600]\tvalid_0's binary_logloss: 1.06744\n",
      "[601]\tvalid_0's binary_logloss: 1.0698\n",
      "[602]\tvalid_0's binary_logloss: 1.06753\n",
      "[603]\tvalid_0's binary_logloss: 1.07857\n",
      "[604]\tvalid_0's binary_logloss: 1.07585\n",
      "[605]\tvalid_0's binary_logloss: 1.07338\n",
      "[606]\tvalid_0's binary_logloss: 1.07136\n",
      "[607]\tvalid_0's binary_logloss: 1.06862\n",
      "[608]\tvalid_0's binary_logloss: 1.07189\n",
      "[609]\tvalid_0's binary_logloss: 1.07663\n",
      "[610]\tvalid_0's binary_logloss: 1.0828\n",
      "[611]\tvalid_0's binary_logloss: 1.09073\n",
      "[612]\tvalid_0's binary_logloss: 1.09705\n",
      "[613]\tvalid_0's binary_logloss: 1.09493\n",
      "[614]\tvalid_0's binary_logloss: 1.09909\n",
      "[615]\tvalid_0's binary_logloss: 1.10076\n",
      "[616]\tvalid_0's binary_logloss: 1.10857\n",
      "[617]\tvalid_0's binary_logloss: 1.10638\n",
      "[618]\tvalid_0's binary_logloss: 1.0995\n",
      "[619]\tvalid_0's binary_logloss: 1.09758\n",
      "[620]\tvalid_0's binary_logloss: 1.10076\n",
      "[621]\tvalid_0's binary_logloss: 1.09875\n",
      "[622]\tvalid_0's binary_logloss: 1.09634\n",
      "[623]\tvalid_0's binary_logloss: 1.09652\n",
      "[624]\tvalid_0's binary_logloss: 1.09414\n",
      "[625]\tvalid_0's binary_logloss: 1.09407\n",
      "[626]\tvalid_0's binary_logloss: 1.1017\n",
      "[627]\tvalid_0's binary_logloss: 1.11143\n",
      "[628]\tvalid_0's binary_logloss: 1.11638\n",
      "[629]\tvalid_0's binary_logloss: 1.11404\n",
      "[630]\tvalid_0's binary_logloss: 1.11168\n",
      "[631]\tvalid_0's binary_logloss: 1.11598\n",
      "[632]\tvalid_0's binary_logloss: 1.11999\n",
      "[633]\tvalid_0's binary_logloss: 1.11769\n",
      "[634]\tvalid_0's binary_logloss: 1.11551\n",
      "[635]\tvalid_0's binary_logloss: 1.11511\n",
      "[636]\tvalid_0's binary_logloss: 1.11997\n",
      "[637]\tvalid_0's binary_logloss: 1.12497\n",
      "[638]\tvalid_0's binary_logloss: 1.12274\n",
      "[639]\tvalid_0's binary_logloss: 1.11982\n",
      "[640]\tvalid_0's binary_logloss: 1.12817\n",
      "[641]\tvalid_0's binary_logloss: 1.12599\n",
      "[642]\tvalid_0's binary_logloss: 1.12376\n",
      "[643]\tvalid_0's binary_logloss: 1.12922\n",
      "[644]\tvalid_0's binary_logloss: 1.12688\n",
      "[645]\tvalid_0's binary_logloss: 1.13146\n",
      "[646]\tvalid_0's binary_logloss: 1.13829\n",
      "[647]\tvalid_0's binary_logloss: 1.13895\n",
      "[648]\tvalid_0's binary_logloss: 1.14566\n",
      "[649]\tvalid_0's binary_logloss: 1.14318\n",
      "[650]\tvalid_0's binary_logloss: 1.14135\n",
      "[651]\tvalid_0's binary_logloss: 1.14294\n",
      "[652]\tvalid_0's binary_logloss: 1.14095\n",
      "[653]\tvalid_0's binary_logloss: 1.13834\n",
      "[654]\tvalid_0's binary_logloss: 1.13612\n",
      "[655]\tvalid_0's binary_logloss: 1.13748\n",
      "[656]\tvalid_0's binary_logloss: 1.14234\n",
      "[657]\tvalid_0's binary_logloss: 1.14057\n",
      "[658]\tvalid_0's binary_logloss: 1.14337\n",
      "[659]\tvalid_0's binary_logloss: 1.14136\n",
      "[660]\tvalid_0's binary_logloss: 1.14783\n",
      "[661]\tvalid_0's binary_logloss: 1.14566\n",
      "[662]\tvalid_0's binary_logloss: 1.14589\n",
      "[663]\tvalid_0's binary_logloss: 1.14408\n",
      "[664]\tvalid_0's binary_logloss: 1.14156\n",
      "[665]\tvalid_0's binary_logloss: 1.1399\n",
      "[666]\tvalid_0's binary_logloss: 1.13789\n",
      "[667]\tvalid_0's binary_logloss: 1.13548\n",
      "[668]\tvalid_0's binary_logloss: 1.13311\n",
      "[669]\tvalid_0's binary_logloss: 1.13792\n",
      "[670]\tvalid_0's binary_logloss: 1.1357\n",
      "[671]\tvalid_0's binary_logloss: 1.13381\n",
      "[672]\tvalid_0's binary_logloss: 1.14201\n",
      "[673]\tvalid_0's binary_logloss: 1.13951\n",
      "[674]\tvalid_0's binary_logloss: 1.14465\n",
      "[675]\tvalid_0's binary_logloss: 1.14811\n",
      "[676]\tvalid_0's binary_logloss: 1.15092\n",
      "[677]\tvalid_0's binary_logloss: 1.15506\n",
      "[678]\tvalid_0's binary_logloss: 1.15322\n",
      "[679]\tvalid_0's binary_logloss: 1.15559\n",
      "[680]\tvalid_0's binary_logloss: 1.16085\n",
      "[681]\tvalid_0's binary_logloss: 1.1586\n",
      "[682]\tvalid_0's binary_logloss: 1.15678\n",
      "[683]\tvalid_0's binary_logloss: 1.16017\n",
      "[684]\tvalid_0's binary_logloss: 1.16525\n",
      "[685]\tvalid_0's binary_logloss: 1.1626\n",
      "[686]\tvalid_0's binary_logloss: 1.16753\n",
      "[687]\tvalid_0's binary_logloss: 1.16515\n",
      "[688]\tvalid_0's binary_logloss: 1.16257\n",
      "[689]\tvalid_0's binary_logloss: 1.16596\n",
      "[690]\tvalid_0's binary_logloss: 1.16932\n",
      "[691]\tvalid_0's binary_logloss: 1.16682\n",
      "[692]\tvalid_0's binary_logloss: 1.16443\n",
      "[693]\tvalid_0's binary_logloss: 1.16958\n",
      "[694]\tvalid_0's binary_logloss: 1.17071\n",
      "[695]\tvalid_0's binary_logloss: 1.16877\n",
      "[696]\tvalid_0's binary_logloss: 1.16871\n",
      "[697]\tvalid_0's binary_logloss: 1.16894\n",
      "[698]\tvalid_0's binary_logloss: 1.16582\n",
      "[699]\tvalid_0's binary_logloss: 1.16314\n",
      "[700]\tvalid_0's binary_logloss: 1.16446\n",
      "[701]\tvalid_0's binary_logloss: 1.16842\n",
      "[702]\tvalid_0's binary_logloss: 1.16926\n",
      "[703]\tvalid_0's binary_logloss: 1.1671\n",
      "[704]\tvalid_0's binary_logloss: 1.16489\n",
      "[705]\tvalid_0's binary_logloss: 1.16267\n",
      "[706]\tvalid_0's binary_logloss: 1.16072\n",
      "[707]\tvalid_0's binary_logloss: 1.15866\n",
      "[708]\tvalid_0's binary_logloss: 1.16237\n",
      "[709]\tvalid_0's binary_logloss: 1.1574\n",
      "[710]\tvalid_0's binary_logloss: 1.15702\n",
      "[711]\tvalid_0's binary_logloss: 1.15493\n",
      "[712]\tvalid_0's binary_logloss: 1.15267\n",
      "[713]\tvalid_0's binary_logloss: 1.15689\n",
      "[714]\tvalid_0's binary_logloss: 1.16458\n",
      "[715]\tvalid_0's binary_logloss: 1.16233\n",
      "[716]\tvalid_0's binary_logloss: 1.16755\n",
      "[717]\tvalid_0's binary_logloss: 1.16538\n",
      "[718]\tvalid_0's binary_logloss: 1.1636\n",
      "[719]\tvalid_0's binary_logloss: 1.16132\n",
      "[720]\tvalid_0's binary_logloss: 1.15959\n",
      "[721]\tvalid_0's binary_logloss: 1.16353\n",
      "[722]\tvalid_0's binary_logloss: 1.16163\n",
      "[723]\tvalid_0's binary_logloss: 1.16061\n",
      "[724]\tvalid_0's binary_logloss: 1.16006\n",
      "[725]\tvalid_0's binary_logloss: 1.15779\n",
      "[726]\tvalid_0's binary_logloss: 1.16047\n",
      "[727]\tvalid_0's binary_logloss: 1.16071\n",
      "[728]\tvalid_0's binary_logloss: 1.16674\n",
      "[729]\tvalid_0's binary_logloss: 1.16446\n",
      "[730]\tvalid_0's binary_logloss: 1.16452\n",
      "[731]\tvalid_0's binary_logloss: 1.16223\n",
      "[732]\tvalid_0's binary_logloss: 1.16004\n",
      "[733]\tvalid_0's binary_logloss: 1.15629\n",
      "[734]\tvalid_0's binary_logloss: 1.15414\n",
      "[735]\tvalid_0's binary_logloss: 1.16037\n",
      "[736]\tvalid_0's binary_logloss: 1.15826\n",
      "[737]\tvalid_0's binary_logloss: 1.15651\n",
      "[738]\tvalid_0's binary_logloss: 1.1597\n",
      "[739]\tvalid_0's binary_logloss: 1.16243\n",
      "[740]\tvalid_0's binary_logloss: 1.16737\n",
      "[741]\tvalid_0's binary_logloss: 1.16624\n",
      "[742]\tvalid_0's binary_logloss: 1.17103\n",
      "[743]\tvalid_0's binary_logloss: 1.1695\n",
      "[744]\tvalid_0's binary_logloss: 1.17156\n",
      "[745]\tvalid_0's binary_logloss: 1.16987\n",
      "[746]\tvalid_0's binary_logloss: 1.16815\n",
      "[747]\tvalid_0's binary_logloss: 1.17342\n",
      "[748]\tvalid_0's binary_logloss: 1.17496\n",
      "[749]\tvalid_0's binary_logloss: 1.17331\n",
      "[750]\tvalid_0's binary_logloss: 1.17639\n",
      "[751]\tvalid_0's binary_logloss: 1.17616\n",
      "[752]\tvalid_0's binary_logloss: 1.1741\n",
      "[753]\tvalid_0's binary_logloss: 1.18156\n",
      "[754]\tvalid_0's binary_logloss: 1.17911\n",
      "[755]\tvalid_0's binary_logloss: 1.18302\n",
      "[756]\tvalid_0's binary_logloss: 1.1809\n",
      "[757]\tvalid_0's binary_logloss: 1.17905\n",
      "[758]\tvalid_0's binary_logloss: 1.18523\n",
      "[759]\tvalid_0's binary_logloss: 1.18706\n",
      "[760]\tvalid_0's binary_logloss: 1.185\n",
      "[761]\tvalid_0's binary_logloss: 1.19079\n",
      "[762]\tvalid_0's binary_logloss: 1.19091\n",
      "[763]\tvalid_0's binary_logloss: 1.18927\n",
      "[764]\tvalid_0's binary_logloss: 1.1959\n",
      "[765]\tvalid_0's binary_logloss: 1.19414\n",
      "[766]\tvalid_0's binary_logloss: 1.194\n",
      "[767]\tvalid_0's binary_logloss: 1.19228\n",
      "[768]\tvalid_0's binary_logloss: 1.19007\n",
      "[769]\tvalid_0's binary_logloss: 1.19541\n",
      "[770]\tvalid_0's binary_logloss: 1.19395\n",
      "[771]\tvalid_0's binary_logloss: 1.19208\n",
      "[772]\tvalid_0's binary_logloss: 1.19026\n",
      "[773]\tvalid_0's binary_logloss: 1.18795\n",
      "[774]\tvalid_0's binary_logloss: 1.18642\n",
      "[775]\tvalid_0's binary_logloss: 1.19064\n",
      "[776]\tvalid_0's binary_logloss: 1.19356\n",
      "[777]\tvalid_0's binary_logloss: 1.19331\n",
      "[778]\tvalid_0's binary_logloss: 1.19585\n",
      "[779]\tvalid_0's binary_logloss: 1.19349\n",
      "[780]\tvalid_0's binary_logloss: 1.19165\n",
      "[781]\tvalid_0's binary_logloss: 1.19535\n",
      "[782]\tvalid_0's binary_logloss: 1.20486\n",
      "[783]\tvalid_0's binary_logloss: 1.20249\n",
      "[784]\tvalid_0's binary_logloss: 1.20015\n",
      "[785]\tvalid_0's binary_logloss: 1.20221\n",
      "[786]\tvalid_0's binary_logloss: 1.20047\n",
      "[787]\tvalid_0's binary_logloss: 1.19816\n",
      "[788]\tvalid_0's binary_logloss: 1.19619\n",
      "[789]\tvalid_0's binary_logloss: 1.20112\n",
      "[790]\tvalid_0's binary_logloss: 1.20492\n",
      "[791]\tvalid_0's binary_logloss: 1.20749\n",
      "[792]\tvalid_0's binary_logloss: 1.20528\n",
      "[793]\tvalid_0's binary_logloss: 1.20516\n",
      "[794]\tvalid_0's binary_logloss: 1.20307\n",
      "[795]\tvalid_0's binary_logloss: 1.2054\n",
      "[796]\tvalid_0's binary_logloss: 1.2036\n",
      "[797]\tvalid_0's binary_logloss: 1.20156\n",
      "[798]\tvalid_0's binary_logloss: 1.19959\n",
      "[799]\tvalid_0's binary_logloss: 1.20315\n",
      "[800]\tvalid_0's binary_logloss: 1.20108\n",
      "[801]\tvalid_0's binary_logloss: 1.1973\n",
      "[802]\tvalid_0's binary_logloss: 1.1954\n",
      "[803]\tvalid_0's binary_logloss: 1.19388\n",
      "[804]\tvalid_0's binary_logloss: 1.19171\n",
      "[805]\tvalid_0's binary_logloss: 1.19008\n",
      "[806]\tvalid_0's binary_logloss: 1.18832\n",
      "[807]\tvalid_0's binary_logloss: 1.18931\n",
      "[808]\tvalid_0's binary_logloss: 1.19753\n",
      "[809]\tvalid_0's binary_logloss: 1.19606\n",
      "[810]\tvalid_0's binary_logloss: 1.20108\n",
      "[811]\tvalid_0's binary_logloss: 1.20201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[812]\tvalid_0's binary_logloss: 1.20042\n",
      "[813]\tvalid_0's binary_logloss: 1.20619\n",
      "[814]\tvalid_0's binary_logloss: 1.20452\n",
      "[815]\tvalid_0's binary_logloss: 1.20985\n",
      "[816]\tvalid_0's binary_logloss: 1.2145\n",
      "[817]\tvalid_0's binary_logloss: 1.21249\n",
      "[818]\tvalid_0's binary_logloss: 1.21476\n",
      "[819]\tvalid_0's binary_logloss: 1.21322\n",
      "[820]\tvalid_0's binary_logloss: 1.21104\n",
      "[821]\tvalid_0's binary_logloss: 1.21366\n",
      "[822]\tvalid_0's binary_logloss: 1.21166\n",
      "[823]\tvalid_0's binary_logloss: 1.20987\n",
      "[824]\tvalid_0's binary_logloss: 1.21178\n",
      "[825]\tvalid_0's binary_logloss: 1.21216\n",
      "[826]\tvalid_0's binary_logloss: 1.21063\n",
      "[827]\tvalid_0's binary_logloss: 1.20874\n",
      "[828]\tvalid_0's binary_logloss: 1.2104\n",
      "[829]\tvalid_0's binary_logloss: 1.214\n",
      "[830]\tvalid_0's binary_logloss: 1.21308\n",
      "[831]\tvalid_0's binary_logloss: 1.21244\n",
      "[832]\tvalid_0's binary_logloss: 1.21522\n",
      "[833]\tvalid_0's binary_logloss: 1.22094\n",
      "[834]\tvalid_0's binary_logloss: 1.21902\n",
      "[835]\tvalid_0's binary_logloss: 1.21742\n",
      "[836]\tvalid_0's binary_logloss: 1.21904\n",
      "[837]\tvalid_0's binary_logloss: 1.21938\n",
      "[838]\tvalid_0's binary_logloss: 1.2165\n",
      "[839]\tvalid_0's binary_logloss: 1.22277\n",
      "[840]\tvalid_0's binary_logloss: 1.22568\n",
      "[841]\tvalid_0's binary_logloss: 1.22871\n",
      "[842]\tvalid_0's binary_logloss: 1.23825\n",
      "[843]\tvalid_0's binary_logloss: 1.24034\n",
      "[844]\tvalid_0's binary_logloss: 1.23825\n",
      "[845]\tvalid_0's binary_logloss: 1.23574\n",
      "[846]\tvalid_0's binary_logloss: 1.23378\n",
      "[847]\tvalid_0's binary_logloss: 1.23702\n",
      "[848]\tvalid_0's binary_logloss: 1.23472\n",
      "[849]\tvalid_0's binary_logloss: 1.23297\n",
      "[850]\tvalid_0's binary_logloss: 1.23477\n",
      "[851]\tvalid_0's binary_logloss: 1.2333\n",
      "[852]\tvalid_0's binary_logloss: 1.2405\n",
      "[853]\tvalid_0's binary_logloss: 1.23918\n",
      "[854]\tvalid_0's binary_logloss: 1.2376\n",
      "[855]\tvalid_0's binary_logloss: 1.24733\n",
      "[856]\tvalid_0's binary_logloss: 1.24665\n",
      "[857]\tvalid_0's binary_logloss: 1.24549\n",
      "[858]\tvalid_0's binary_logloss: 1.24357\n",
      "[859]\tvalid_0's binary_logloss: 1.24191\n",
      "[860]\tvalid_0's binary_logloss: 1.24861\n",
      "[861]\tvalid_0's binary_logloss: 1.2509\n",
      "[862]\tvalid_0's binary_logloss: 1.2566\n",
      "[863]\tvalid_0's binary_logloss: 1.25522\n",
      "[864]\tvalid_0's binary_logloss: 1.25346\n",
      "[865]\tvalid_0's binary_logloss: 1.25554\n",
      "[866]\tvalid_0's binary_logloss: 1.26269\n",
      "[867]\tvalid_0's binary_logloss: 1.26495\n",
      "[868]\tvalid_0's binary_logloss: 1.26306\n",
      "[869]\tvalid_0's binary_logloss: 1.2673\n",
      "[870]\tvalid_0's binary_logloss: 1.26536\n",
      "[871]\tvalid_0's binary_logloss: 1.26366\n",
      "[872]\tvalid_0's binary_logloss: 1.26834\n",
      "[873]\tvalid_0's binary_logloss: 1.26627\n",
      "[874]\tvalid_0's binary_logloss: 1.26418\n",
      "[875]\tvalid_0's binary_logloss: 1.26183\n",
      "[876]\tvalid_0's binary_logloss: 1.26246\n",
      "[877]\tvalid_0's binary_logloss: 1.26125\n",
      "[878]\tvalid_0's binary_logloss: 1.26345\n",
      "[879]\tvalid_0's binary_logloss: 1.26183\n",
      "[880]\tvalid_0's binary_logloss: 1.25978\n",
      "[881]\tvalid_0's binary_logloss: 1.25782\n",
      "[882]\tvalid_0's binary_logloss: 1.26339\n",
      "[883]\tvalid_0's binary_logloss: 1.26166\n",
      "[884]\tvalid_0's binary_logloss: 1.26906\n",
      "[885]\tvalid_0's binary_logloss: 1.26976\n",
      "[886]\tvalid_0's binary_logloss: 1.26736\n",
      "[887]\tvalid_0's binary_logloss: 1.2733\n",
      "[888]\tvalid_0's binary_logloss: 1.27489\n",
      "[889]\tvalid_0's binary_logloss: 1.27306\n",
      "[890]\tvalid_0's binary_logloss: 1.27655\n",
      "[891]\tvalid_0's binary_logloss: 1.28104\n",
      "[892]\tvalid_0's binary_logloss: 1.28121\n",
      "[893]\tvalid_0's binary_logloss: 1.27989\n",
      "[894]\tvalid_0's binary_logloss: 1.28089\n",
      "[895]\tvalid_0's binary_logloss: 1.2792\n",
      "[896]\tvalid_0's binary_logloss: 1.27775\n",
      "[897]\tvalid_0's binary_logloss: 1.27586\n",
      "[898]\tvalid_0's binary_logloss: 1.27394\n",
      "[899]\tvalid_0's binary_logloss: 1.27885\n",
      "[900]\tvalid_0's binary_logloss: 1.28161\n",
      "[901]\tvalid_0's binary_logloss: 1.28008\n",
      "[902]\tvalid_0's binary_logloss: 1.27865\n",
      "[903]\tvalid_0's binary_logloss: 1.28371\n",
      "[904]\tvalid_0's binary_logloss: 1.28756\n",
      "[905]\tvalid_0's binary_logloss: 1.28592\n",
      "[906]\tvalid_0's binary_logloss: 1.28351\n",
      "[907]\tvalid_0's binary_logloss: 1.28754\n",
      "[908]\tvalid_0's binary_logloss: 1.28561\n",
      "[909]\tvalid_0's binary_logloss: 1.28431\n",
      "[910]\tvalid_0's binary_logloss: 1.2819\n",
      "[911]\tvalid_0's binary_logloss: 1.28688\n",
      "[912]\tvalid_0's binary_logloss: 1.28515\n",
      "[913]\tvalid_0's binary_logloss: 1.2831\n",
      "[914]\tvalid_0's binary_logloss: 1.28547\n",
      "[915]\tvalid_0's binary_logloss: 1.28104\n",
      "[916]\tvalid_0's binary_logloss: 1.27912\n",
      "[917]\tvalid_0's binary_logloss: 1.27742\n",
      "[918]\tvalid_0's binary_logloss: 1.27565\n",
      "[919]\tvalid_0's binary_logloss: 1.27349\n",
      "[920]\tvalid_0's binary_logloss: 1.27161\n",
      "[921]\tvalid_0's binary_logloss: 1.26976\n",
      "[922]\tvalid_0's binary_logloss: 1.26814\n",
      "[923]\tvalid_0's binary_logloss: 1.26658\n",
      "[924]\tvalid_0's binary_logloss: 1.27113\n",
      "[925]\tvalid_0's binary_logloss: 1.27208\n",
      "[926]\tvalid_0's binary_logloss: 1.27658\n",
      "[927]\tvalid_0's binary_logloss: 1.27491\n",
      "[928]\tvalid_0's binary_logloss: 1.27284\n",
      "[929]\tvalid_0's binary_logloss: 1.27213\n",
      "[930]\tvalid_0's binary_logloss: 1.27633\n",
      "[931]\tvalid_0's binary_logloss: 1.27426\n",
      "[932]\tvalid_0's binary_logloss: 1.27267\n",
      "[933]\tvalid_0's binary_logloss: 1.27407\n",
      "[934]\tvalid_0's binary_logloss: 1.26873\n",
      "[935]\tvalid_0's binary_logloss: 1.2682\n",
      "[936]\tvalid_0's binary_logloss: 1.26606\n",
      "[937]\tvalid_0's binary_logloss: 1.26427\n",
      "[938]\tvalid_0's binary_logloss: 1.2672\n",
      "[939]\tvalid_0's binary_logloss: 1.26539\n",
      "[940]\tvalid_0's binary_logloss: 1.2724\n",
      "[941]\tvalid_0's binary_logloss: 1.2708\n",
      "[942]\tvalid_0's binary_logloss: 1.27514\n",
      "[943]\tvalid_0's binary_logloss: 1.27328\n",
      "[944]\tvalid_0's binary_logloss: 1.27342\n",
      "[945]\tvalid_0's binary_logloss: 1.27161\n",
      "[946]\tvalid_0's binary_logloss: 1.27074\n",
      "[947]\tvalid_0's binary_logloss: 1.27493\n",
      "[948]\tvalid_0's binary_logloss: 1.27747\n",
      "[949]\tvalid_0's binary_logloss: 1.27474\n",
      "[950]\tvalid_0's binary_logloss: 1.28005\n",
      "[951]\tvalid_0's binary_logloss: 1.27874\n",
      "[952]\tvalid_0's binary_logloss: 1.27715\n",
      "[953]\tvalid_0's binary_logloss: 1.27523\n",
      "[954]\tvalid_0's binary_logloss: 1.27365\n",
      "[955]\tvalid_0's binary_logloss: 1.27275\n",
      "[956]\tvalid_0's binary_logloss: 1.27825\n",
      "[957]\tvalid_0's binary_logloss: 1.28337\n",
      "[958]\tvalid_0's binary_logloss: 1.28163\n",
      "[959]\tvalid_0's binary_logloss: 1.28435\n",
      "[960]\tvalid_0's binary_logloss: 1.28769\n",
      "[961]\tvalid_0's binary_logloss: 1.29062\n",
      "[962]\tvalid_0's binary_logloss: 1.29257\n",
      "[963]\tvalid_0's binary_logloss: 1.29056\n",
      "[964]\tvalid_0's binary_logloss: 1.28891\n",
      "[965]\tvalid_0's binary_logloss: 1.29286\n",
      "[966]\tvalid_0's binary_logloss: 1.29128\n",
      "[967]\tvalid_0's binary_logloss: 1.28969\n",
      "[968]\tvalid_0's binary_logloss: 1.28778\n",
      "[969]\tvalid_0's binary_logloss: 1.28609\n",
      "[970]\tvalid_0's binary_logloss: 1.28852\n",
      "[971]\tvalid_0's binary_logloss: 1.28764\n",
      "[972]\tvalid_0's binary_logloss: 1.28667\n",
      "[973]\tvalid_0's binary_logloss: 1.28474\n",
      "[974]\tvalid_0's binary_logloss: 1.28292\n",
      "[975]\tvalid_0's binary_logloss: 1.28115\n",
      "[976]\tvalid_0's binary_logloss: 1.28032\n",
      "[977]\tvalid_0's binary_logloss: 1.2785\n",
      "[978]\tvalid_0's binary_logloss: 1.28174\n",
      "[979]\tvalid_0's binary_logloss: 1.28034\n",
      "[980]\tvalid_0's binary_logloss: 1.27592\n",
      "[981]\tvalid_0's binary_logloss: 1.27433\n",
      "[982]\tvalid_0's binary_logloss: 1.27279\n",
      "[983]\tvalid_0's binary_logloss: 1.27721\n",
      "[984]\tvalid_0's binary_logloss: 1.27887\n",
      "[985]\tvalid_0's binary_logloss: 1.27741\n",
      "[986]\tvalid_0's binary_logloss: 1.27566\n",
      "[987]\tvalid_0's binary_logloss: 1.27405\n",
      "[988]\tvalid_0's binary_logloss: 1.27658\n",
      "[989]\tvalid_0's binary_logloss: 1.27487\n",
      "[990]\tvalid_0's binary_logloss: 1.27365\n",
      "[991]\tvalid_0's binary_logloss: 1.27494\n",
      "[992]\tvalid_0's binary_logloss: 1.27155\n",
      "[993]\tvalid_0's binary_logloss: 1.26954\n",
      "[994]\tvalid_0's binary_logloss: 1.2689\n",
      "[995]\tvalid_0's binary_logloss: 1.26738\n",
      "[996]\tvalid_0's binary_logloss: 1.2732\n",
      "[997]\tvalid_0's binary_logloss: 1.27761\n",
      "[998]\tvalid_0's binary_logloss: 1.27602\n",
      "[999]\tvalid_0's binary_logloss: 1.27779\n",
      "[1000]\tvalid_0's binary_logloss: 1.27655\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "train_data = lightgbm.Dataset(Train_Features, label=np.squeeze(Train_Target))\n",
    "val_data = lightgbm.Dataset(Val_Features, label=np.squeeze(Val_Target))\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'dart',#'gbdt' 'dart'\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 30,\n",
    "    'verbose': 2,\n",
    "}\n",
    "\n",
    "dart = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=val_data,\n",
    "                       num_boost_round=1000,\n",
    "                       early_stopping_rounds=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.897181729834791\n"
     ]
    }
   ],
   "source": [
    "preds_dart=dart.predict(Test_Features)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, preds_dart)\n",
    "print(\"AUC: \" + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  93  12\n",
      "1  15  83\n",
      "True Positives: 83\n",
      "True Negatives: 93\n",
      "False Positives: 12\n",
      "False Negatives: 15\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.87\n",
      "Mis-Classification: 0.13\n",
      "Sensitivity: 0.85\n",
      "Specificity: 0.89\n",
      "Precision: 0.89\n",
      "f_1 Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "confusion_metrics(Y_test,np.round(preds_dart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestdartmmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump((dart), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KMeans\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6134991e-03 2.1081895e-03 0.0000000e+00 ... 1.7568034e-01\n",
      "  8.0918729e-02 2.6544614e+00]\n",
      " [8.0086337e-04 1.2054585e-03 1.5514814e-08 ... 8.4059513e-01\n",
      "  1.2176312e+00 1.2046247e+00]\n",
      " [1.1649001e-03 1.4998619e-03 3.6504311e-08 ... 7.9408073e-01\n",
      "  4.5360473e-01 1.0286644e+00]]\n"
     ]
    }
   ],
   "source": [
    "# create kmeans object\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "# fit kmeans object to data\n",
    "kmeans.fit(Train_Features)\n",
    "# print location of clusters learned by kmeans object\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_km = kmeans.fit_predict(Train_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = kmeans.fit_predict(Test_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 2 2 2 2 2 2 2 2 2 2 1 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 2 2 0 2 2 2 0 1 1 2 2 2 2\n",
      " 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 2 2 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds_dart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "di={'actual':Y_test,'preds_xgboost':preds_xgb,'preds_rf':preds_rf,\n",
    "   'preds_bdt':preds_bdt,'preds_adaboost':preds_adaboost,'preds_gbdt':np.round(preds_gbdt),'preds_dart':np.round(preds_dart)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>preds_xgboost</th>\n",
       "      <th>preds_rf</th>\n",
       "      <th>preds_bdt</th>\n",
       "      <th>preds_adaboost</th>\n",
       "      <th>preds_gbdt</th>\n",
       "      <th>preds_dart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  preds_xgboost  preds_rf  preds_bdt  preds_adaboost  preds_gbdt  \\\n",
       "0         1              1         1          1               1         1.0   \n",
       "1         1              1         1          1               0         1.0   \n",
       "2         1              1         1          1               1         1.0   \n",
       "3         1              1         1          1               1         1.0   \n",
       "4         1              1         1          1               1         1.0   \n",
       "5         1              1         1          1               1         1.0   \n",
       "6         1              1         1          1               1         1.0   \n",
       "7         1              1         1          1               1         1.0   \n",
       "8         1              1         1          1               1         1.0   \n",
       "9         1              1         1          1               0         0.0   \n",
       "10        1              1         1          1               0         1.0   \n",
       "11        1              0         1          1               0         0.0   \n",
       "12        1              1         1          1               1         1.0   \n",
       "13        1              1         1          1               0         1.0   \n",
       "14        1              0         0          0               0         0.0   \n",
       "15        1              0         0          0               0         0.0   \n",
       "16        1              1         1          1               1         1.0   \n",
       "17        1              1         1          1               1         1.0   \n",
       "18        1              1         1          1               0         1.0   \n",
       "19        1              1         1          1               1         1.0   \n",
       "20        1              1         1          1               1         1.0   \n",
       "21        1              1         1          1               1         1.0   \n",
       "22        1              1         1          1               1         1.0   \n",
       "23        1              1         1          1               1         1.0   \n",
       "24        1              1         1          1               1         1.0   \n",
       "25        1              1         1          1               1         1.0   \n",
       "26        1              1         1          1               1         1.0   \n",
       "27        1              1         1          1               0         1.0   \n",
       "28        1              1         1          1               1         1.0   \n",
       "29        1              1         1          1               1         1.0   \n",
       "..      ...            ...       ...        ...             ...         ...   \n",
       "173       0              1         0          1               1         1.0   \n",
       "174       0              0         0          0               0         0.0   \n",
       "175       0              1         1          0               1         0.0   \n",
       "176       0              0         0          0               1         0.0   \n",
       "177       0              0         0          0               0         0.0   \n",
       "178       0              0         0          0               0         0.0   \n",
       "179       0              1         1          1               1         1.0   \n",
       "180       0              1         1          1               1         1.0   \n",
       "181       0              0         1          1               0         1.0   \n",
       "182       0              1         1          1               1         1.0   \n",
       "183       0              1         1          1               0         1.0   \n",
       "184       0              0         0          0               0         0.0   \n",
       "185       0              0         1          0               0         0.0   \n",
       "186       0              0         0          0               0         0.0   \n",
       "187       0              0         0          0               0         0.0   \n",
       "188       0              0         0          0               0         0.0   \n",
       "189       0              0         0          0               0         0.0   \n",
       "190       0              0         0          0               0         0.0   \n",
       "191       0              0         0          0               0         0.0   \n",
       "192       0              0         0          0               0         0.0   \n",
       "193       0              0         0          0               0         0.0   \n",
       "194       0              0         0          0               0         0.0   \n",
       "195       0              0         0          0               0         0.0   \n",
       "196       0              0         0          0               0         0.0   \n",
       "197       0              0         0          0               0         0.0   \n",
       "198       0              0         0          0               0         0.0   \n",
       "199       0              0         0          0               0         0.0   \n",
       "200       0              1         1          1               1         1.0   \n",
       "201       0              1         1          1               1         1.0   \n",
       "202       0              0         0          0               0         0.0   \n",
       "\n",
       "     preds_dart  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           1.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "5           1.0  \n",
       "6           1.0  \n",
       "7           1.0  \n",
       "8           1.0  \n",
       "9           1.0  \n",
       "10          1.0  \n",
       "11          0.0  \n",
       "12          1.0  \n",
       "13          1.0  \n",
       "14          0.0  \n",
       "15          0.0  \n",
       "16          1.0  \n",
       "17          1.0  \n",
       "18          1.0  \n",
       "19          1.0  \n",
       "20          1.0  \n",
       "21          1.0  \n",
       "22          1.0  \n",
       "23          1.0  \n",
       "24          1.0  \n",
       "25          1.0  \n",
       "26          1.0  \n",
       "27          1.0  \n",
       "28          1.0  \n",
       "29          1.0  \n",
       "..          ...  \n",
       "173         1.0  \n",
       "174         0.0  \n",
       "175         1.0  \n",
       "176         0.0  \n",
       "177         0.0  \n",
       "178         0.0  \n",
       "179         1.0  \n",
       "180         1.0  \n",
       "181         0.0  \n",
       "182         0.0  \n",
       "183         0.0  \n",
       "184         0.0  \n",
       "185         0.0  \n",
       "186         0.0  \n",
       "187         0.0  \n",
       "188         0.0  \n",
       "189         0.0  \n",
       "190         0.0  \n",
       "191         0.0  \n",
       "192         0.0  \n",
       "193         0.0  \n",
       "194         0.0  \n",
       "195         0.0  \n",
       "196         0.0  \n",
       "197         0.0  \n",
       "198         0.0  \n",
       "199         0.0  \n",
       "200         1.0  \n",
       "201         1.0  \n",
       "202         0.0  \n",
       "\n",
       "[203 rows x 7 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
